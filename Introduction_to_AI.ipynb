{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sethkipsangmutuba/Artificial-Intelligence/blob/main/Introduction_to_AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. Understanding Artificial Intelligence (AI)**\n",
        "Artificial Intelligence (AI) is the science of creating systems that can perform tasks requiring human-like intelligence, such as **learning, reasoning, problem-solving, perception, and natural language processing**.\n",
        "\n",
        "AI is deeply embedded in our daily activities, including:\n",
        "- **Internet searches** (Google’s ranking algorithms)\n",
        "- **Face recognition** (smartphones, security systems)\n",
        "- **Speech-to-text conversion** (Siri, Google Assistant)\n",
        "- **Recommendation systems** (Netflix, Amazon, YouTube)\n",
        "- **Autonomous Vehicles** (self-driving cars)\n",
        "\n",
        "### **1.1 Why Study AI?**\n",
        "- AI **automates complex decision-making** and enhances efficiency.\n",
        "- It **optimizes big data** for business insights and predictions.\n",
        "- AI drives **technological advancements** in robotics, healthcare, and finance.\n",
        "- Understanding AI allows us to **build smarter applications** to solve real-world problems.\n",
        "\n",
        "---\n",
        "\n",
        "## **2. AI in Data Science & Industry Applications**\n",
        "AI plays a significant role across various industries:\n",
        "- **Healthcare**: AI-assisted diagnostics, robotic surgeries, predictive analytics.\n",
        "- **Finance**: Fraud detection, stock market predictions, risk assessment.\n",
        "- **Retail & E-Commerce**: Personalized recommendations, automated chatbots.\n",
        "- **Autonomous Systems**: Self-driving cars, AI-powered drones, robotic automation.\n",
        "- **Cybersecurity**: AI-powered threat detection and prevention.\n",
        "\n",
        "---\n",
        "\n",
        "## **3. Python for AI: Essential Libraries & Setup**\n",
        "### **3.1 Python Programming for AI**\n",
        "Python is the most widely used language for AI and ML due to its simplicity and vast ecosystem of libraries.\n",
        "\n",
        "### **3.2 Setting Up Your AI Development Environment**\n",
        "- Install **Python 3**: [Download Here](https://www.python.org/)\n",
        "- Use **virtual environments** (`venv`, `pip`, `conda`) for package management.\n",
        "- Install **Jupyter Notebook** for an interactive coding environment.\n",
        "- Set up **GitHub** for version control and project collaboration.\n",
        "\n",
        "### **3.3 Essential Python Libraries for AI**\n",
        "| **Library** | **Purpose** |\n",
        "|------------|-------------|\n",
        "| **NumPy** | Numerical computing, matrix operations |\n",
        "| **Pandas** | Data preprocessing & manipulation |\n",
        "| **Matplotlib & Seaborn** | Data visualization & exploratory analysis |\n",
        "| **Scikit-Learn** | Machine learning algorithms & models |\n",
        "| **TensorFlow/PyTorch** | Deep learning frameworks |\n",
        "\n",
        "---\n",
        "\n",
        "## **4. Mathematical Foundations for AI**\n",
        "Mathematics is the backbone of AI, enabling model development and optimization.\n",
        "\n",
        "### **4.1 Linear Algebra for AI**\n",
        "- **Vectors & Matrices**: Used to store and manipulate data in ML models.\n",
        "- **Eigenvalues & Eigenvectors**: Used in **Principal Component Analysis (PCA)**.\n",
        "- **Matrix Operations**: Transposition, inversion, determinants in ML.\n",
        "\n",
        "### **4.2 Probability & Statistics in AI**\n",
        "- **Bayes' Theorem**: Used in spam detection and predictive modeling.\n",
        "- **Gaussian Distributions**: Common in data modeling and anomaly detection.\n",
        "- **Statistical Inference**: Hypothesis testing and confidence intervals.\n",
        "\n",
        "### **4.3 Optimization Techniques for AI Models**\n",
        "Optimization helps AI models improve their predictions.\n",
        "- **Gradient Descent**: Algorithm for finding optimal parameters in ML.\n",
        "- **Adam, RMSprop**: Advanced optimizers for deep learning.\n",
        "- **Loss Functions**: Mean Squared Error (MSE), Cross-Entropy.\n",
        "\n",
        "### **4.4 Vector Calculus for AI**\n",
        "- **Derivatives & Gradients**: Core of optimization algorithms.\n",
        "- **Backpropagation**: Key mechanism in training neural networks.\n",
        "- **Hessian & Jacobian Matrices**: Higher-order optimization in AI.\n",
        "\n",
        "---\n",
        "\n",
        "## **5. Capstone Project Kickoff: Defining a Real-World AI Problem**\n",
        "\n",
        "####**submit by sunday date 2/03/2025**\n",
        "A **capstone project** will help apply AI concepts to real-world problems.\n",
        "\n",
        "### **5.1 Project Planning**\n",
        "- **Define the problem statement**: Identify a relevant AI challenge.\n",
        "- **Gather and preprocess data**: Use Python libraries like Pandas & NumPy.\n",
        "- **Set evaluation metrics**: Define success criteria for the project.\n",
        "\n",
        "### **5.2 Exploratory Data Analysis (EDA)**\n",
        "- **Data visualization**: Use Matplotlib & Seaborn to explore patterns.\n",
        "- **Feature selection**: Choose relevant data features for AI models.\n",
        "- **Data cleaning**: Handle missing values, outliers, and normalization.\n",
        "\n",
        "---\n",
        "\n",
        "## **6. Hands-on Exercises**\n",
        "### **6.1 Setting Up Python & GitHub**\n",
        "- Install required Python libraries.\n",
        "- Set up Jupyter Notebook for coding.\n",
        "- Upload and manage projects on GitHub.\n",
        "\n",
        "### **6.2 Implementing Basic AI Models**\n",
        "#### **Linear Regression using NumPy & Scikit-Learn**\n",
        "- Train a simple regression model.\n",
        "- Predict outcomes and evaluate model performance.\n",
        "\n",
        "#### **Simple Classification Model with TensorFlow**\n",
        "- Implement a basic neural network classifier.\n",
        "- Train on labeled datasets and visualize results.\n",
        "\n",
        "### **6.3 Visualizing AI Models**\n",
        "- Plot loss curves to track training progress.\n",
        "- Generate decision boundaries in classification models.\n",
        "\n",
        "---\n",
        "\n",
        "## **7. Week 1 Outcome**\n",
        "By the end of this week, you will:\n",
        "- Understand AI’s role in different industries.  \n",
        "- Set up Python, Jupyter Notebook, and GitHub for AI development.  \n",
        "- Gain mathematical knowledge essential for AI models.  \n",
        "- Implement basic AI models using Python & TensorFlow.  \n",
        "- Define and plan a real-world AI capstone project.  \n"
      ],
      "metadata": {
        "id": "KJuwmCBnHdhm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **What is Artificial Intelligence?**  \n",
        "\n",
        "Artificial Intelligence (AI) enables machines to **think, learn, and act intelligently**. It involves developing **software** that mimics **human reasoning, decision-making, and problem-solving**.  \n",
        "\n",
        "### **Key Aspects of AI**  \n",
        "AI focuses on making machines:  \n",
        "- **Sense** their environment  \n",
        "- **Reason** based on data  \n",
        "- **Think** like humans  \n",
        "- **Act** rationally  \n",
        "\n",
        "### **AI & Human Intelligence**  \n",
        "AI is inspired by the **human brain**, aiming to replicate how it **learns and makes decisions**.  \n",
        "By understanding human cognition, researchers create **intelligent systems** capable of **autonomous learning and adaptation**.  \n"
      ],
      "metadata": {
        "id": "Y5UllfZ1HhCB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Why Do We Need to Study AI?**  \n",
        "\n",
        "AI impacts **every aspect of life** by recognizing patterns, automating tasks, and enhancing intelligence.  \n",
        "\n",
        "## **AI vs. Human Intelligence**  \n",
        "\n",
        "| **Human Brain**                           | **Artificial Intelligence**                   |\n",
        "|-------------------------------------------|----------------------------------------------|\n",
        "| Recognizes objects, understands language | Learns from data, mimics human thinking     |\n",
        "| Processes information effortlessly        | Requires algorithms & computations          |\n",
        "| Adapts to new situations                  | Continuously improves through training      |\n",
        "| Limited by biological constraints         | Can scale infinitely with computational power |\n",
        "\n",
        "## **Challenges in the Modern World**  \n",
        "\n",
        "| **Challenges**                          | **How AI Solves Them**                          |\n",
        "|-----------------------------------------|-----------------------------------------------|\n",
        "| **Massive, unstructured data**         | Processes large datasets efficiently        |\n",
        "| **Multiple data sources**               | Ingests real-time data simultaneously       |\n",
        "| **Constantly changing information**    | Learns & updates continuously               |\n",
        "| **Need for real-time decisions**       | Responds instantly with high precision      |\n",
        "\n",
        "## **AI's Role in Automation & Efficiency**  \n",
        "\n",
        "| **AI Capabilities**                     | **Impact**                                  |\n",
        "|-----------------------------------------|-------------------------------------------|\n",
        "| **Data processing & analysis**         | Generates insights from complex data     |\n",
        "| **Machine learning & adaptation**      | Continuously improves decision-making    |\n",
        "| **Real-time response & precision**     | Enhances speed & accuracy in applications |\n",
        "| **Smart automation**                   | Reduces human effort & increases efficiency |\n",
        "\n",
        "AI is **revolutionizing industries** by making machines **smarter, faster, and more efficient**.\n"
      ],
      "metadata": {
        "id": "GEJZvaAnHlIZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Applications of AI**  \n",
        "\n",
        "AI is transforming various industries by enabling machines to **see, hear, understand, and make decisions**.  \n",
        "\n",
        "## **Key AI Applications Across Industries**  \n",
        "\n",
        "| **Application**                 | **Description**                                         | **Examples** |\n",
        "|---------------------------------|---------------------------------------------------------|-------------|\n",
        "| **Computer Vision**             | Analyzes visual data (images/videos)                   | Reverse image search, facial recognition, autonomous vehicles |\n",
        "| **Natural Language Processing (NLP)** | Understands and processes human language       | Search engines, chatbots, sentiment analysis |\n",
        "| **Speech Recognition**          | Converts spoken language into text                     | Virtual assistants (Siri, Alexa), voice-controlled devices |\n",
        "| **Expert Systems**              | Uses AI to provide expert-level advice and decisions   | Medical diagnosis, financial forecasting |\n",
        "| **AI in Games**                 | Develops intelligent agents for gaming                 | AlphaGo, adaptive AI in video games |\n",
        "| **Robotics**                    | Builds AI-powered robots with sensors and actuators    | Industrial automation, autonomous drones |\n",
        "\n",
        "AI continues to **expand rapidly**, shaping the future of technology across multiple domains.  \n"
      ],
      "metadata": {
        "id": "EOtUFaKFHlxj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Branches of AI**  \n",
        "\n",
        "AI consists of multiple specialized fields that address different types of problems.  \n",
        "\n",
        "## **Key Branches of AI**  \n",
        "\n",
        "| **Branch**                     | **Description**                                         | **Applications** |\n",
        "|---------------------------------|---------------------------------------------------------|------------------|\n",
        "| **Machine Learning (ML)**       | AI learns patterns from data and makes predictions     | Face recognition, recommendation systems |\n",
        "| **Logic-Based AI**              | Uses mathematical logic to solve problems              | Language parsing, semantic analysis |\n",
        "| **Search Algorithms**           | Examines possibilities to find the best solution       | Chess, networking, resource allocation |\n",
        "| **Knowledge Representation**    | Organizes facts and relationships in a structured way  | Expert systems, ontology-based AI |\n",
        "| **Planning**                    | Develops optimal strategies to achieve goals          | Autonomous robotics, logistics optimization |\n",
        "| **Heuristics**                  | Uses practical problem-solving methods for quick results | Search engines, robotics navigation |\n",
        "| **Genetic Programming**         | Evolves AI models by mimicking natural selection      | AI optimization, automated software generation |\n",
        "\n",
        "Each **AI branch** focuses on a different problem-solving approach, making AI highly **versatile and powerful**.\n"
      ],
      "metadata": {
        "id": "m5JUSqNPHn6a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Defining Intelligence Using the Turing Test**  \n",
        "\n",
        "Alan Turing proposed the **Turing Test** to define intelligence by evaluating whether a machine can mimic human behavior in a conversation.  \n",
        "\n",
        "## **Turing Test Setup**  \n",
        "\n",
        "| **Component**               | **Description** |\n",
        "|----------------------------|----------------|\n",
        "| **Interrogator (Human)**   | Asks questions via a text interface |\n",
        "| **Respondents**            | One human and one machine |\n",
        "| **Objective**              | The machine must mimic human responses well enough to fool the interrogator |\n",
        "\n",
        "### **Core AI Areas Required to Pass the Test**  \n",
        "\n",
        "| **AI Domain**                  | **Role in the Turing Test** |\n",
        "|--------------------------------|----------------------------|\n",
        "| **Natural Language Processing (NLP)** | Helps the machine understand and generate human-like responses |\n",
        "| **Knowledge Representation**   | Stores and retrieves information relevant to the conversation |\n",
        "| **Reasoning**                  | Interprets and processes information logically |\n",
        "| **Machine Learning**           | Adapts and improves responses based on experience |\n",
        "\n",
        "### **Extended Turing Test Variants**  \n",
        "\n",
        "| **Test Type**         | **Additional Requirements** |\n",
        "|----------------------|---------------------------|\n",
        "| **Standard Turing Test** | Machine communicates via text only |\n",
        "| **Total Turing Test** | Machine must also see objects (**Computer Vision**) and move (**Robotics**) |\n",
        "\n",
        "Turing believed that **physical appearance** was **not necessary** for intelligence, which is why the original test only used **text-based interaction**.  \n",
        "\n",
        "Understanding the **Turing Test** provides insight into AI’s ability to **replicate human-like intelligence**!  \n"
      ],
      "metadata": {
        "id": "W96e7dJ3HsXa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Making Machines Think Like Humans**  \n",
        "\n",
        "To make machines think like humans, we must first understand **human thought processes**.  \n",
        "\n",
        "## **Approaches to Understanding Human Thinking**  \n",
        "\n",
        "| **Approach**                    | **Description** |\n",
        "|----------------------------------|----------------|\n",
        "| **Observing Human Responses**    | Recording human behavior and reactions, but this becomes complex with too much data |\n",
        "| **Experimentation**              | Creating structured questions and analyzing human responses to build a model |\n",
        "\n",
        "Once enough **data is gathered**, we develop **AI models** that mimic human cognition. If the **output** aligns with **human behavior**, we can say that machines are thinking similarly to humans.  \n",
        "\n",
        "## **Cognitive Modeling in AI**  \n",
        "\n",
        "| **Concept**                    | **Role in AI** |\n",
        "|---------------------------------|----------------|\n",
        "| **Cognitive Modeling**         | Simulates human thought processes in AI systems |\n",
        "| **Problem-Solving Simulation** | Models how humans approach and solve problems |\n",
        "| **AI Applications**            | Used in **Deep Learning, Expert Systems, NLP, and Robotics** |\n",
        "\n",
        "Cognitive modeling helps build AI systems that can **reason, learn, and adapt**, making them **more human-like** in thinking and decision-making!  \n"
      ],
      "metadata": {
        "id": "iIbnSnfVHs-M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Building Rational Agents**  \n",
        "\n",
        "AI research focuses on creating **rational agents** that act based on **rationality**—choosing actions that maximize benefits in a given situation.  \n",
        "\n",
        "## **Key Concepts of Rational Agents**  \n",
        "\n",
        "| **Concept**        | **Definition** |\n",
        "|--------------------|---------------|\n",
        "| **Rationality**    | Doing the **right thing** based on available information |\n",
        "| **Agent**         | An entity that perceives and acts in an environment |\n",
        "| **Rational Agent** | Takes actions to achieve goals efficiently and intelligently |\n",
        "\n",
        "## **How Rational Agents Work**  \n",
        "\n",
        "| **Step**              | **Description** |\n",
        "|----------------------|----------------|\n",
        "| **Perception**       | Agent **receives input** from its environment |\n",
        "| **Processing**       | It **analyzes** information based on predefined rules |\n",
        "| **Action**          | Takes the **best possible action** to achieve its goal |\n",
        "\n",
        "## **Performance Measure of Rational Agents**  \n",
        "\n",
        "| **Factor**              | **Impact on Rationality** |\n",
        "|------------------------|-------------------------|\n",
        "| **Success Rate**       | Measures how well the agent **achieves its goal** |\n",
        "| **Inference Ability**  | Ability to **draw correct conclusions** from information |\n",
        "| **Handling Uncertainty** | Acts even in situations where no perfect solution exists |\n",
        "\n",
        "A **rational agent** should **adapt to new environments**, **make logical decisions**, and **optimize performance** to achieve its objectives efficiently."
      ],
      "metadata": {
        "id": "NSMSMAw5HvOI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Problem Solver (GPS)**  \n",
        "\n",
        "The **General Problem Solver (GPS)** was an AI program developed by **Herbert Simon, J.C. Shaw, and Allen Newell**. It was one of the first **universal problem-solving** systems in AI. Unlike earlier programs designed for specific tasks, GPS aimed to solve **any general problem** using a **single algorithm**.  \n",
        "\n",
        "## **Key Features of GPS**  \n",
        "\n",
        "| **Feature**                 | **Description** |\n",
        "|-----------------------------|---------------|\n",
        "| **Universal Problem Solving** | Designed to solve **various types of problems** using the same algorithm |\n",
        "| **Information Processing Language (IPL)** | Custom language created to define problem structures |\n",
        "| **Graph-Based Approach** | Problems represented as **graphs** with **sources (axioms)** and **sinks (conclusions)** |\n",
        "| **Brute Force Search** | Used search algorithms to explore **possible solutions**, but faced scalability issues |\n",
        "\n",
        "## **Limitations of GPS**  \n",
        "\n",
        "| **Limitation**              | **Impact** |\n",
        "|----------------------------|------------|\n",
        "| **Only Solves Well-Defined Problems** | Could handle **mathematical proofs, logic puzzles, and chess**, but struggled with real-world tasks |\n",
        "| **Computational Complexity** | Required **excessive resources** to brute force large problem spaces |\n",
        "| **Predefined Problem Structure** | Required problems to be framed in a **specific logical format** |\n",
        "\n",
        "## **Example: Solving a Problem with GPS**  \n",
        "\n",
        "**Goal:** Get milk from a grocery store.  \n",
        "\n",
        "| **Step** | **Description** |\n",
        "|----------|---------------|\n",
        "| **Define Goals** | The objective is to **buy milk** from the store. |\n",
        "| **Set Preconditions** | - Need a **mode of transportation**.<br>- Grocery store must **have milk available**. |\n",
        "| **Define Operators** | - If using a car, check **fuel availability**.<br>- Ensure **payment capability** for both fuel and milk. |\n",
        "\n",
        "GPS used a **search-based approach**, evaluating **all possible actions** to determine the best way to achieve a goal. However, due to **computational complexity**, it struggled with **large-scale real-world applications**."
      ],
      "metadata": {
        "id": "fHFKgU97Hxqz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Building an Intelligent Agent**  \n",
        "\n",
        "To build an **intelligent agent**, we use various techniques like **machine learning, stored knowledge, and rule-based systems**. Among these, **machine learning** is the most widely used method, allowing agents to learn from **data and training**.  \n",
        "\n",
        "## **How an Intelligent Agent Interacts with the Environment**  \n",
        "\n",
        " **Sensor Perception** → Collects data from the environment.  \n",
        " **Feature Extraction** → Identifies relevant patterns from the input data.  \n",
        " **Inference Engine** → Uses a **trained machine learning model** to make predictions.  \n",
        " **Decision Making** → Based on predictions, it determines the best action.  \n",
        " **Actuator Execution** → Performs the necessary real-world action.  \n",
        "\n",
        "## **Applications of Intelligent Agents**  \n",
        "\n",
        "| **Application**         | **Use Case** |\n",
        "|-------------------------|-------------|\n",
        "| **Image Recognition**   | Facial recognition, object detection |\n",
        "| **Robotics**            | Autonomous vehicles, industrial automation |\n",
        "| **Speech Recognition**  | Voice assistants, real-time transcription |\n",
        "| **Stock Market Prediction** | Financial forecasting and trend analysis |\n",
        "\n",
        "## **Key Concepts in Machine Learning for Intelligent Agents**  \n",
        "\n",
        "| **Concept**               | **Description** |\n",
        "|---------------------------|---------------|\n",
        "| **Pattern Recognition**   | Identifying trends and structures in data |\n",
        "| **Artificial Neural Networks** | Mimicking the human brain for complex decision-making |\n",
        "| **Data Mining**           | Extracting useful insights from large datasets |\n",
        "| **Statistics**            | Understanding probabilities and data distributions |\n",
        "\n",
        "By integrating **machine learning**, intelligent agents can **continuously improve** and make **better decisions** over time.\n"
      ],
      "metadata": {
        "id": "42AZMTMuHz4z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Types of Models in AI**  \n",
        "\n",
        "AI models can be categorized into two main types: **Analytical Models** and **Learned Models**.  \n",
        "\n",
        "# **Types of Models in AI**  \n",
        "\n",
        "AI models can be categorized into two main types: **Analytical Models** and **Learned Models**.  \n",
        "\n",
        "## **Comparison Table**  \n",
        "\n",
        "| **Model Type**        | **Definition**  | **Characteristics**  | **Advantages**  | **Limitations**  | **Example Use Cases**  |\n",
        "|----------------------|----------------|---------------------|-----------------|------------------|------------------------|\n",
        "| **Analytical Models**  | Traditional models based on mathematical formulas to describe relationships. | - Based on human judgment  <br> - Uses predefined equations  <br> - Simplistic with few parameters  | - Interpretable & explainable  <br> - Works well for simple systems  | - Limited accuracy  <br> - Cannot handle large datasets efficiently  | Physics-based simulations, financial forecasting with linear models  |\n",
        "| **Learned Models**  | Models trained using data rather than predefined formulas. | - Learns patterns from data  <br> - Uses machine learning  <br> - Highly complex with many parameters  | - Handles large datasets  <br> - High accuracy  <br> - Can adapt to new data  | - Requires large amounts of data  <br> - Computationally expensive  | Image recognition, speech processing, autonomous driving |\n",
        "\n",
        "## **Machine Learning and Learned Models**  \n",
        "Machine learning allows AI to automatically **discover patterns and relationships** from data, replacing the need for manually derived formulas.  \n",
        "\n",
        "- **Labeled Inputs** – Features provided to the model  \n",
        "- **Corresponding Outputs** – Desired results  \n",
        "\n",
        "Once trained, AI models can **predict outcomes** based on unseen inputs.  \n"
      ],
      "metadata": {
        "id": "A1_CqCS6H3_L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import necessary libraries\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "\n",
        "# Step 2: Load the dataset\n",
        "data = fetch_california_housing()\n",
        "data"
      ],
      "metadata": {
        "id": "lx7ISV5EH4mG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decr attribute"
      ],
      "metadata": {
        "id": "bl-Bt9IeH9b1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.DESCR"
      ],
      "metadata": {
        "id": "bAa4y95rIAxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the first five rows of data\n",
        "print(\"First 5 rows of the dataset:\\n\", data.data[:20])"
      ],
      "metadata": {
        "id": "UdfI23lrIG1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **California Housing Dataset**  \n",
        "\n",
        "The **California Housing Dataset** is a regression dataset derived from the **1990 U.S. Census**, containing **20,640 instances** with **8 numerical features** and **no missing values**.  \n",
        "\n",
        "## **Key Features:**  \n",
        "- Represents **block groups** (smallest U.S. Census units) with populations between **600–3,000 people**.  \n",
        "- Attributes include:  \n",
        "  - **MedInc** → Median income in block group  \n",
        "  - **HouseAge** → Median house age  \n",
        "  - **AveRooms** → Average rooms per household  \n",
        "  - **AveBedrms** → Average bedrooms per household  \n",
        "  - **Population** → Block group population  \n",
        "  - **AveOccup** → Average household members  \n",
        "  - **Latitude** → Block group latitude  \n",
        "  - **Longitude** → Block group longitude  \n",
        "- **Target Variable:** Median house value (in **$100,000 units**).  \n",
        "\n"
      ],
      "metadata": {
        "id": "6NCuY3z-ITpy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to DataFrame for easy handling\n",
        "import pandas as pd\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "df"
      ],
      "metadata": {
        "id": "X1QZeYW5IXdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "OHltDiBJIbyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "anzUj_hqIhtM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.duplicated().sum()"
      ],
      "metadata": {
        "id": "VtxF7VgfIiSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "km3W8fGdIk1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "5pNFM8PsIqRv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the target variable (house value)\n",
        "df['Target'] = data.target\n",
        "df['Target']"
      ],
      "metadata": {
        "id": "9ZwKRaY6Iruk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "# Plot the distribution of the target variable\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.histplot(df['HouseAge'], bins=30, kde=True, color='blue')\n",
        "plt.title(\"Distribution of Median House Values\")\n",
        "plt.xlabel(\"Median House Value (in $100,000s)\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Z3K4BKm-Iyzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the distribution of the target variable\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.histplot(df['Population'], bins=30, kde=True, color='blue')\n",
        "plt.title(\"Distribution of Median House Values\")\n",
        "plt.xlabel(\"Median House Value (in $100,000s)\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t3sSN01MIzZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Plot correlation heatmap\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.heatmap(df.corr(), annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title(\"Feature Correlation Heatmap\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bLpygJI8I12C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.corr()"
      ],
      "metadata": {
        "id": "lYKEgia4I6e2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define features (X) and target (y)\n",
        "X = df.drop(columns=['Target'])\n",
        "X"
      ],
      "metadata": {
        "id": "-di2tYkyI7Tf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = df['Target']\n",
        "y"
      ],
      "metadata": {
        "id": "nGfJVQzRI_BB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split dataset into training (80%) and testing (20%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train"
      ],
      "metadata": {
        "id": "yGXMy049JBwk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test"
      ],
      "metadata": {
        "id": "QTyTGt6tJEVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "id": "sKJkLN7LJJ-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "id": "5ms2jgUbJMow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "id": "zB54ViimJNg7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "id": "3QYdrHFpJQQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "scaler"
      ],
      "metadata": {
        "id": "SU3jBFD4JTfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_train_scaled"
      ],
      "metadata": {
        "id": "UJHjJvqkJXA4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_scaled = scaler.transform(X_test)\n",
        "X_test_scaled"
      ],
      "metadata": {
        "id": "RV0VArARJZ7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "# Train a linear regression model\n",
        "model = LinearRegression()\n",
        "model"
      ],
      "metadata": {
        "id": "9CfX6j_2JcWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_scaled, y_train)"
      ],
      "metadata": {
        "id": "2zR_z57IJetq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "y_pred"
      ],
      "metadata": {
        "id": "NX4B1cTNJhVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# Calculate error metrics\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mae"
      ],
      "metadata": {
        "id": "du0_iXB1JjgW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "rmse = np.sqrt(mse)\n",
        "rmse"
      ],
      "metadata": {
        "id": "-LGD4XNGJlw-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "r2"
      ],
      "metadata": {
        "id": "WQ1aRYVEJq0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Scatter plot of actual vs. predicted values\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.scatterplot(x=y_test, y=y_pred, alpha=0.5, color='red')\n",
        "plt.plot([0, 7], [0, 7], '--', color='blue')  # Ideal prediction line\n",
        "plt.xlabel(\"Actual Median House Value\")\n",
        "plt.ylabel(\"Predicted Median House Value\")\n",
        "plt.title(\"Actual vs. Predicted House Values\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CsZ5aAHuJtGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Performance Evaluation\n",
        "\n",
        "The model's performance is assessed using several key metrics:\n",
        "\n",
        "- **Mean Absolute Error (MAE):** **0.5332**  \n",
        "  - On average, the model's predictions deviate by **$53,320** from actual house prices.\n",
        "\n",
        "- **Mean Squared Error (MSE):** **0.5559**  \n",
        "  - Represents the squared differences between predicted and actual values, emphasizing larger errors.\n",
        "\n",
        "- **Root Mean Squared Error (RMSE):** **0.7456**  \n",
        "  - The typical prediction error is around **$74,560**, making it more interpretable than MSE.\n",
        "\n",
        "- **R-squared Score (R²):** **0.5758**  \n",
        "  - Indicates that the model explains about **57.58% of the variance** in house prices.  \n",
        "  - While this suggests moderate accuracy, further improvements can be made.\n",
        "\n",
        "### Possible Enhancements:\n",
        "- Refining feature selection for better input variables.\n",
        "- Experimenting with polynomial regression for capturing complex relationships.\n",
        "- Trying advanced models like Decision Trees, Random Forests, or Neural Networks for improved predictive power.\n"
      ],
      "metadata": {
        "id": "1l2nBf-JJxhp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Create a pipeline with feature scaling and a RandomForest model\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('model', RandomForestRegressor(n_estimators=100, random_state=42))\n",
        "])\n",
        "\n",
        "# Hyperparameter tuning with GridSearchCV\n",
        "param_grid = {\n",
        "    'model__n_estimators': [50, 100, 200],\n",
        "    'model__max_depth': [None, 10, 20]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='r2', n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "ko6Il7fOJy55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the best model\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "y_pred"
      ],
      "metadata": {
        "id": "H4trjeZxJ1cN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute evaluation metrics\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mae"
      ],
      "metadata": {
        "id": "-tMs4OtaJ3jL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mse = mean_squared_error(y_test, y_pred)\n",
        "mse"
      ],
      "metadata": {
        "id": "NOHogUTiJ5x7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rmse = np.sqrt(mse)\n",
        "rmse"
      ],
      "metadata": {
        "id": "uaXgMFgEJ77n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r2 = r2_score(y_test, y_pred)\n",
        "r2"
      ],
      "metadata": {
        "id": "FlAZvG2UJ-XQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Extract feature importance from the trained Random Forest model\n",
        "feature_importance = best_model.named_steps['model'].feature_importances_\n",
        "feature_importance"
      ],
      "metadata": {
        "id": "H3uKhu3LKCut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Import necessary library for interactive plotting\n",
        "import plotly.express as px\n",
        "\n",
        "# Retrieve feature names from the dataset (ensure X is a DataFrame)\n",
        "feature_names = X.columns\n",
        "feature_names"
      ],
      "metadata": {
        "id": "jg9z2NwQKD3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Create a DataFrame to store feature names and their importance scores\n",
        "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importance})\n",
        "importance_df"
      ],
      "metadata": {
        "id": "eJtRcjGxKGPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort features by importance in descending order for better visualization\n",
        "importance_df = importance_df.sort_values(by='Importance', ascending=True)\n",
        "importance_df"
      ],
      "metadata": {
        "id": "nIWnf0r0KJP8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "\n",
        "# Create an interactive horizontal bar chart using Plotly Express\n",
        "fig = px.bar(importance_df,\n",
        "             x='Importance',\n",
        "             y='Feature',\n",
        "             orientation='h',  # Horizontal bar chart\n",
        "             title=\"Feature Importance in Random Forest Model\",\n",
        "             labels={'Importance': 'Importance Score', 'Feature': 'Feature'},\n",
        "             color='Importance',  # Color based on importance values\n",
        "             color_continuous_scale='viridis')  # Use Viridis color scale\n",
        "# Show the interactive plot\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "yhZWE2MrKLtk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute residuals (errors)\n",
        "residuals = y_test - y_pred\n",
        "residuals"
      ],
      "metadata": {
        "id": "iAVazf4UKOR1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Plot histogram of residuals\n",
        "fig_hist = px.histogram(residuals,\n",
        "                        nbins=50,\n",
        "                        title=\"Residual Distribution\",\n",
        "                        labels={'value': 'Residuals'},\n",
        "                        marginal=\"box\",  # Add boxplot for distribution insight\n",
        "                        color_discrete_sequence=['royalblue'])\n",
        "\n",
        "fig_hist.show()"
      ],
      "metadata": {
        "id": "FwIpNroMKQjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scatter plot of residuals vs. predicted values\n",
        "fig_scatter = px.scatter(x=y_pred,\n",
        "                          y=residuals,\n",
        "                          title=\"Residuals vs. Predicted Values\",\n",
        "                          labels={'x': 'Predicted Values', 'y': 'Residuals'},\n",
        "                          color=residuals,\n",
        "                          color_continuous_scale='viridis')\n",
        "\n",
        "# Add a horizontal reference line at y=0 (no error)\n",
        "fig_scatter.add_hline(y=0, line_dash=\"dash\", line_color=\"red\")\n",
        "\n",
        "fig_scatter.show()"
      ],
      "metadata": {
        "id": "y3vvUNT8KS3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "# Compute Variance Inflation Factor (VIF)\n",
        "vif_data = pd.DataFrame()\n",
        "vif_data[\"Feature\"] = X.columns\n",
        "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        "vif_data[\"VIF\"]"
      ],
      "metadata": {
        "id": "LaUny6tuKVQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import plotly.express as px\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#  Sort and display VIF results\n",
        "vif_data = vif_data.sort_values(by=\"VIF\", ascending=True)\n",
        "fig_vif = px.bar(vif_data, x=\"VIF\", y=\"Feature\", title=\"Variance Inflation Factor (VIF) for Features\", orientation=\"h\", color=\"VIF\", color_continuous_scale=\"viridis\")\n",
        "fig_vif.show()\n"
      ],
      "metadata": {
        "id": "JpOpeLW6KYCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Interpreting Variance Inflation Factor (VIF) Results**\n",
        "\n",
        "**If VIF is low (<5)** → No multicollinearity issues, features are independent.  \n",
        "\n",
        "**If VIF is high (>5 or 10)** → Some features might be redundant and should be removed or transformed.  \n",
        "\n",
        "**If correlations are strong** → Consider feature selection techniques such as **Principal Component Analysis (PCA)** or **Lasso Regression** to reduce dimensionality.  "
      ],
      "metadata": {
        "id": "zSgerkflKdcJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "import numpy as np\n",
        "\n",
        "# Function to calculate VIF\n",
        "def calculate_vif(X):\n",
        "    vif_data = pd.DataFrame()\n",
        "    vif_data[\"Feature\"] = X.columns\n",
        "    vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        "    return vif_data\n",
        "\n",
        "# Compute VIF\n",
        "vif_df = calculate_vif(X)\n",
        "\n",
        "# Drop features with high VIF (>5)\n",
        "high_vif_features = vif_df[vif_df[\"VIF\"] > 5][\"Feature\"].tolist()\n",
        "X_selected = X.drop(columns=high_vif_features)\n",
        "\n",
        "print(\"Dropped Features:\", high_vif_features)"
      ],
      "metadata": {
        "id": "Ac5LHj5DKgOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Reduce dimensionality while keeping 95% variance\n",
        "pca = PCA(n_components=0.95)\n",
        "X_pca = pca.fit_transform(X_selected)\n",
        "\n",
        "print(\"New Shape after PCA:\", X_pca.shape)"
      ],
      "metadata": {
        "id": "rG18pSAHKir_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "# Apply Lasso Regression to select important features\n",
        "lasso = Lasso(alpha=0.01)  # Adjust alpha based on need\n",
        "lasso.fit(X_selected, y)\n",
        "\n",
        "# Select features with non-zero coefficients\n",
        "selected_features = X_selected.columns[lasso.coef_ != 0]\n",
        "X_lasso = X_selected[selected_features]\n",
        "\n",
        "print(\"Selected Features after Lasso:\", selected_features.tolist())\n"
      ],
      "metadata": {
        "id": "cqFRdw7vKjf6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}